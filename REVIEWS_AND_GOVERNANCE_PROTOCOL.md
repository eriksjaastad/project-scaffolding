# üõ°Ô∏è Ecosystem Governance & Review Protocol (v1.2)

**Date:** 2026-01-24
**Status:** ACTIVE
**Goal:** Transition from "Rapid Experimentation" to "Industrial-Grade Hardening."

---

## üèõÔ∏è Part 1: The Core Architecture (Checklist-First)
*Intelligence belongs in the checklist, not the prompt.*

### 1. The Fundamental Pivot
Prompts are subjective and mood-dependent; checklists are versioned, auditable specifications of what "reviewed" means.
*   **Evidence-First Rule:** Every check requires an evidence field (e.g., a `grep` output). Empty evidence = Incomplete Review.
*   **The Artifact:** The review deliverable is a completed evidence trail, not an unstructured prose opinion.

### 2. The Blast Radius Prioritization
Audit files in order of their potential to infect the ecosystem:
1.  **Tier 1: Propagation Sources (Highest Impact):** `templates/`, `.cursorrules`, `AGENTS.md`. If these fail, every downstream project inherits the defect.
2.  **Tier 2: Execution Critical:** `scripts/`, `scaffold/`. These run the automation but don't propagate DNA.
3.  **Tier 3: Documentation:** `Documents/`, `patterns/`. Important for humans, zero impact on code execution.

---

## üèõÔ∏è Part 2: The Two-Layer Defense Model

### Layer 1: Robotic Scan (Gatekeeper)
A mechanical script (`pre_review_scan.sh`) that catches hardcoded paths, secrets, and silent errors. A single "FAIL" blocks the AI/Human review. This is integrated into the `Project-workflow.md` (lives at projects root) as the mandatory Gate 0.

### Layer 2: Cognitive Audit (Architect Work)
AI Architects focus on judgment-heavy tasks that automation misses:
*   **Inverse Test Analysis:** For every passing test, document what is **NOT** being checked. Identify the "Dark Territory."
*   **Temporal Risk Analysis:** Identify what breaks in 1, 6, or 12 months (e.g., unpinned dependencies, API deprecations).
*   **Propagation Impact:** Verify that Tier 1 files contain no machine-specific assumptions.

---

## üèõÔ∏è Part 3: The Industrial Hardening Audit
*Mandatory checks for projects transitioning from Prototype to Production.*

### 1. The "Data Clobber" Guard
Reviewers must verify that any script writing to global or external paths (e.g., `agent-skills-library`) includes:
*   **Path Validation:** Explicit check that the destination directory exists and is valid.
*   **Dry-Run Mandate:** A `--dry-run` flag that parses all logic but performs zero disk writes.
*   **Safety Gate:** Refuse to write if the `target_path` is not explicitly validated against a whitelist of project roots.

### 2. Subprocess Integrity
Every `subprocess.run` call must follow the **Production Standard**:
*   `check=True`: Fail loudly on non-zero exit codes.
*   `timeout=X`: Never allow a subprocess to hang indefinitely (e.g., `yt-dlp` or `ollama` hangs).
*   `capture_output=True`: Ensure stdout/stderr are captured for telemetry if a failure occurs.

### 3. Frontmatter & Schema Validation
For projects that generate files:
*   **Schema Enforcement:** Generated markdown must be validated against the project's frontmatter taxonomy.
*   **Escape Verbatim:** Verbatim text (like transcripts) must be escaped or truncated to prevent breaking YAML parser logic.

### 4. Test Fixture Integrity
For projects with filesystem or external dependencies:
*   **Isolation Mandate:** All tests must use temporary directories (`tmp_path`, `tempfile`). No tests should read/write to real project paths.
*   **Realistic Structures:** Fixtures must create file structures that mirror production (not empty dirs or single files).
*   **Mock External Calls:** `subprocess.run`, network calls, and system queries must be mocked to prevent flaky tests.
*   **Composable Fixtures:** Build complex fixtures from simpler ones (e.g., `project_with_wikilinks` builds on `project_with_markdown`).
*   **No Weak Assertions:** Tests must verify specific values and behaviors, not just types. `assert isinstance(result, list)` is insufficient; `assert len(result) > 0` and `assert result[0].field == expected` are required.

### 5. Placeholder Integrity (Gate 2)
Every scaffolded project must be validated for unfilled template placeholders:
*   **The Check:** Run `scripts/validate_project.py` or `scripts/audit_all_projects.py`.
*   **The Standard:** Zero results for `{{VAR}}` patterns in any `.md`, `.py`, or `.sh` files.
*   **The Enforcement:** A single unfilled placeholder triggers a **Scaffolding Failure** alert to Discord.

---

## üèõÔ∏è Part 4: Scalability Analysis
*Reviewers must document the "Ceiling" of the current architecture.*

### 1. The Context Window Limit
Any logic that aggregates multiple files (e.g., `synthesize.py` reading an entire library) must be flagged for:
*   **The Truncation Risk:** When does the library size exceed the LLM's context window?
*   **Strategy:** Is there a Map-Reduce, RAG, or Tiered Synthesis plan for scale?

### 2. Repository Bloat
Audit for logic that dumps massive verbatim data (e.g., 2-hour video transcripts) into the main repository. Recommend strategies for externalizing large assets if they don't serve the core LLM reasoning.

---

## üß† Part 5: Continual Learning (The Control Loop)
*How we turn "Scars" into "Standards."*

### 1. The "Scar Tissue" SLA
Any new defect type found must be added to the **Robotic Scan** and the **Checklist** within **24 hours**.

### 2. Regression Harnessing
Every bug found must result in a **Reproducer Test** in CI. These tests are the "immune system" of the repo.

### 3. Context-Aware "Mission Orders" (RISEN)
Use the **RISEN Framework** (Role, Instructions, Steps, Expectations, Narrowing) to create a behavioral contract for the auditor.

---

## üìã Part 6: The Master Review Checklist (Template)

| ID | Category | Check Item | Evidence Requirement |
|----|----------|------------|----------------------|
| **M1** | **Robot** | No hardcoded `/Users/` or `/home/` paths | Paste `grep` output (all files) |
| **M2** | **Robot** | No silent `except: pass` patterns | Paste `grep` output (Python files) |
| **M3** | **Robot** | No API keys (`sk-...`) in code/templates | Paste `grep` output |
| **M4** | **Robot** | Zero unfilled `{{VAR}}` placeholders | Paste `validate_project.py` output |
| **P1** | **DNA** | Templates contain no machine-specific data | List files checked in `templates/` |
| **P2** | **DNA** | `.cursorrules` is portable | Verify path placeholders used |
| **T1** | **Tests** | Inverse Audit: What do tests MISS? | Map "Dark Territory" |
| **T2** | **Tests** | No weak assertions (`isinstance`, `is not None` alone) | Grep for assertion patterns |
| **T3** | **Tests** | Every public class/function has test coverage | Coverage report or file audit |
| **T4** | **Tests** | External dependencies mocked (subprocess, network) | Verify `@patch` or mock usage |
| **E1** | **Errors** | Exit codes are accurate (non-zero on fail) | Document manual test of failure path |
| **D1** | **Deps** | Dependency versions are pinned/bounded | Paste `requirements.txt` snapshot |
| **H1** | **Hardening**| Subprocess `check=True` and `timeout` used | List files/lines checked |
| **H2** | **Hardening**| Dry-run flag implemented for global writes | Verify `--dry-run` logic exists |
| **H3** | **Hardening**| Atomic writes used for critical file updates | Verify temp-and-rename pattern |
| **H4** | **Hardening**| Path Safety (safe_slug + traversal check) | Verify all user-input paths are sanitized |
| **R1** | **Reviews** | **Active Review Location** | Must be in project root: `CODE_REVIEW_{MODEL}_{VERSION}.md` |
| **R2** | **Reviews** | **Review Archival** | Previous versions MUST be moved to `Documents/archives/reviews/` |
| **S1** | **Scaling** | Context ceiling strategy (Map-Reduce/RAG) | Document the architectural ceiling |
| **S2** | **Scaling** | Memory/OOM guards for unbounded processing | Verify size-aware batching logic |

---

## üõ†Ô∏è Immediate Action Items
- [x] **Task 1:** Finalize `scripts/pre_review_scan.sh` as the mandatory Gate 0.
- [ ] **Task 2:** Refactor `test_scripts_follow_standards.py` to `test_ecosystem_dna_integrity.py`.
- [ ] **Task 3:** Establish the "Vault" protocol for the local `.env` record of API keys.
- [x] **Task 4:** Implement `scripts/audit_all_projects.py` for ecosystem-wide placeholder scanning.

---
**Protocol Authorized by:** The Phase 5 Judge (Super Manager)
**Strategic Alignment:** Infrastructure (Root)

## Related Documentation

- [Project Workflow](../Project-workflow.md) - master workflow at projects root
- [Doppler Secrets Management](Documents/reference/DOPPLER_SECRETS_MANAGEMENT.md) - secrets management
- [Local Model Learnings](Documents/reference/LOCAL_MODEL_LEARNINGS.md) - local AI
- [Automation Reliability](patterns/automation-reliability.md) - automation
- [Tiered AI Sprint Planning](patterns/tiered-ai-sprint-planning.md) - prompt engineering
- [AI Model Cost Comparison](Documents/reference/MODEL_COST_COMPARISON.md) - AI models
- [Safety Systems](patterns/safety-systems.md) - security
- [Agent Skills Library](../agent-skills-library/README.md) - Agent Skills

